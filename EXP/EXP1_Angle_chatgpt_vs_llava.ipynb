{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%pylab inline\n",
    "%autoreload 2\n",
    "\n",
    "    \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import LLMP as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83eb733610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = L.GPImage.figure1('angle')\n",
    "imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"This image contains a simple line drawing that forms an acute angle. Please estimate the angle.\"\n",
    "question += \"Please respond with a possible range not larger than 10 degrees and report just the numbers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer_llava \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mLLaVA\u001b[38;5;241m.\u001b[39mquery(question, image)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer_llava, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT:\u001b[39m\u001b[38;5;124m'\u001b[39m, label)\n",
      "File \u001b[0;32m~/LLMP/EXP/../LLMP/llavaq.py:45\u001b[0m, in \u001b[0;36mLLaVA.query\u001b[0;34m(question, image, model_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(question, image, model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliuhaotian/llava-v1.5-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     42\u001b[0m     disable_torch_init()\n\u001b[0;32m---> 45\u001b[0m     tokenizer, model, image_processor, context_len \u001b[38;5;241m=\u001b[39m load_pretrained_model(\n\u001b[1;32m     46\u001b[0m         model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[1;32m     47\u001b[0m         model_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mget_model_name_from_path(model_path)\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgs\u001b[39m\u001b[38;5;124m'\u001b[39m, (), {\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_path,\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_base\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m     64\u001b[0m     })()\n\u001b[1;32m     68\u001b[0m     qs \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mquery\n",
      "File \u001b[0;32m~/LLMP/LLMP/LLaVA/llava/model/builder.py:114\u001b[0m, in \u001b[0;36mload_pretrained_model\u001b[0;34m(model_path, model_base, model_name, load_8bit, load_4bit, device_map, device, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m             tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 114\u001b[0m             model \u001b[38;5;241m=\u001b[39m LlavaLlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path, low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;66;03m#from transformers import AutoProcessor\u001b[39;00m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;66;03m#processor = AutoProcessor.from_pretrained(\"liuhaotian/llava-v1.5-7b\")\u001b[39;00m\n\u001b[1;32m    117\u001b[0m            \u001b[38;5;66;03m#model = AutoModelForCausalLM.from_pretrained(\"liuhaotian/llava-v1.5-7b\")\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# Load language model\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# PEFT model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLMP/lib/python3.11/site-packages/transformers/modeling_utils.py:3850\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3841\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3842\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3843\u001b[0m     (\n\u001b[1;32m   3844\u001b[0m         model,\n\u001b[1;32m   3845\u001b[0m         missing_keys,\n\u001b[1;32m   3846\u001b[0m         unexpected_keys,\n\u001b[1;32m   3847\u001b[0m         mismatched_keys,\n\u001b[1;32m   3848\u001b[0m         offload_index,\n\u001b[1;32m   3849\u001b[0m         error_msgs,\n\u001b[0;32m-> 3850\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_pretrained_model(\n\u001b[1;32m   3851\u001b[0m         model,\n\u001b[1;32m   3852\u001b[0m         state_dict,\n\u001b[1;32m   3853\u001b[0m         loaded_state_dict_keys,  \u001b[38;5;66;03m# XXX: rename?\u001b[39;00m\n\u001b[1;32m   3854\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3855\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3856\u001b[0m         ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes,\n\u001b[1;32m   3857\u001b[0m         sharded_metadata\u001b[38;5;241m=\u001b[39msharded_metadata,\n\u001b[1;32m   3858\u001b[0m         _fast_init\u001b[38;5;241m=\u001b[39m_fast_init,\n\u001b[1;32m   3859\u001b[0m         low_cpu_mem_usage\u001b[38;5;241m=\u001b[39mlow_cpu_mem_usage,\n\u001b[1;32m   3860\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   3861\u001b[0m         offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[1;32m   3862\u001b[0m         offload_state_dict\u001b[38;5;241m=\u001b[39moffload_state_dict,\n\u001b[1;32m   3863\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[1;32m   3864\u001b[0m         is_quantized\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES),\n\u001b[1;32m   3865\u001b[0m         keep_in_fp32_modules\u001b[38;5;241m=\u001b[39mkeep_in_fp32_modules,\n\u001b[1;32m   3866\u001b[0m     )\n\u001b[1;32m   3868\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3869\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/anaconda3/envs/LLMP/lib/python3.11/site-packages/transformers/modeling_utils.py:3979\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3977\u001b[0m is_safetensors \u001b[38;5;241m=\u001b[39m archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_safetensors:\n\u001b[0;32m-> 3979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3980\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current `device_map` had weights offloaded to the disk. Please provide an `offload_folder`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3981\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for them. Alternatively, make sure you have `safetensors` installed if the model you are using\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3982\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m offers the weights in this format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3983\u001b[0m     )\n\u001b[1;32m   3984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3985\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(offload_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format."
     ]
    }
   ],
   "source": [
    "answer_llava = L.LLaVA.query(question, image)\n",
    "print(answer_llava, 'GT:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-40 GT: 16\n"
     ]
    }
   ],
   "source": [
    "answer_chatgpt2 = L.ChatGPT.query(question, image)\n",
    "print(answer_chatgpt2, 'GT:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
