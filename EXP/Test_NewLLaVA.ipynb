{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281ad640-74ad-4d42-ab31-0c4e0f7f606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt_api_key\n",
      "Initializing LLaVAModel with model_name: llava-hf/llava-1.5-7b-hf\n",
      "Initializing LLaVAModel with model_name: raminguyen/fine-tuned-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cabab63d114593b56187186a5bcb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512101467e90475588d276bddfc02f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f057f02b40aa43c594e2b5fa7f3a702f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f720f58738304886af13afd9bb70ffc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af333c8c6a374cf1b9a9e916e4c54c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4870aa0f2e8434aa00b300199b23cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt': [5], 'llava-1.5-7b-hf': {'run_0': {'raw_answers': ['\\n\\n            USER:  \\n\\n            \\n            This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\\n            \\n            \\nASSISTANT:\\n            \\n            \\n            The angle is approximately 45 degrees.'], 'parsed_answers': [[45.0]], 'mean': 45.0, 'mse': 1600.0, 'mlae': 11.965829368177689, 'times': [5986.274003982544], 'forced_repetitions': 0}, 'run_1': {'raw_answers': ['\\n\\n            USER:  \\n\\n            \\n            This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\\n            \\n            \\nASSISTANT:\\n            \\n            \\n            The angle is approximately 45 degrees.'], 'parsed_answers': [[45.0]], 'mean': 45.0, 'mse': 1600.0, 'mlae': 11.965829368177689, 'times': [4158.349514007568], 'forced_repetitions': 0}, 'run_2': {'raw_answers': ['\\n\\n            USER:  \\n\\n            \\n            This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\\n            \\n            \\nASSISTANT:\\n            \\n            \\n            The angle is approximately 45 degrees.'], 'parsed_answers': [[45.0]], 'mean': 45.0, 'mse': 1600.0, 'mlae': 11.965829368177689, 'times': [4046.7066764831543], 'forced_repetitions': 0}, 'average_mlae': 11.965829368177689, 'std': 0.0}, 'CustomLLaVA': {'run_0': {'raw_answers': ['<s> [INST] <image> \\nThis image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number. [/INST] 1 </s>'], 'parsed_answers': [[1.0]], 'mean': 1.0, 'mse': 16.0, 'mlae': 8.644306961545581, 'times': [5794.437885284424], 'forced_repetitions': 0}, 'run_1': {'raw_answers': ['<s> [INST] <image> \\nThis image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number. [/INST] 1 </s>'], 'parsed_answers': [[1.0]], 'mean': 1.0, 'mse': 16.0, 'mlae': 8.644306961545581, 'times': [6353.981018066406], 'forced_repetitions': 0}, 'run_2': {'raw_answers': ['<s> [INST] <image> \\nThis image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number. [/INST] 1 </s>'], 'parsed_answers': [[1.0]], 'mean': 1.0, 'mse': 16.0, 'mlae': 8.644306961545581, 'times': [5662.2724533081055], 'forced_repetitions': 0}, 'average_mlae': 8.644306961545581, 'std': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "# Add the parent directory to the system path for module imports\n",
    "sys.path.append('../')\n",
    "\n",
    "import LLMP as L\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Clear CUDA cache if using GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "LLaVA = L.NewLLaVAModel(\"llava-hf/llava-1.5-7b-hf\")\n",
    "customLLaVA = L.NewLLaVAModel(\"raminguyen/fine-tuned-data\")\n",
    "\n",
    "\n",
    "# Add them to a dictionary for easy access\n",
    "model_instances = {\n",
    "    \"llava-1.5-7b-hf\": LLaVA, \n",
    "    \"CustomLLaVA\": customLLaVA\n",
    "}\n",
    "\n",
    "# Define query and images\n",
    "query = \"This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\"\n",
    "images = [L.GPImage.figure1('angle') for i in range(1)]\n",
    "\n",
    "# Run the evaluator\n",
    "result1 = L.Evaluator.run(images, query, model_instances)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e319f-3fdb-4852-8935-f7a858c13871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d141078f-5453-4786-9a8f-11baa69ea910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt_api_key\n",
      "/home/kenichi.maeda001/LLMP/EXP\n",
      "Initializing LLaVAModel with model_name: llava-hf/llava-1.5-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6e515bb6134dbc9bc3dd0ed0567eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c10850ccb2f4b25af26c59a420ea508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21def8ec407488d89e3223b4c8e613a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt': [23], 'llava-1.5-7b-hf': {'run_0': {'raw_answers': ['\\n\\n            USER:  \\n\\n            \\n            This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\\n            \\n            \\nASSISTANT:\\n            \\n            \\n            The angle is approximately 45 degrees.'], 'parsed_answers': [[45.0]], 'mean': 45.0, 'mse': 484.0, 'mlae': 11.10336977739252, 'times': [20041.637897491455], 'forced_repetitions': 0}, 'run_1': {'raw_answers': ['\\n\\n            USER:  \\n\\n            \\n            This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\\n            \\n            \\nASSISTANT:\\n            \\n            \\n            The angle is approximately 45 degrees.'], 'parsed_answers': [[45.0]], 'mean': 45.0, 'mse': 484.0, 'mlae': 11.10336977739252, 'times': [4595.969200134277], 'forced_repetitions': 0}, 'run_2': {'raw_answers': ['\\n\\n            USER:  \\n\\n            \\n            This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\\n            \\n            \\nASSISTANT:\\n            \\n            \\n            The angle is approximately 45 degrees.'], 'parsed_answers': [[45.0]], 'mean': 45.0, 'mse': 484.0, 'mlae': 11.10336977739252, 'times': [4019.162178039551], 'forced_repetitions': 0}, 'average_mlae': 11.10336977739252, 'std': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "# Add the parent directory to the system path for module imports\n",
    "sys.path.append('../')\n",
    "\n",
    "import LLMP as L\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Clear CUDA cache if using GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "LLaVA = L.NewLLaVAModel(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "\n",
    "# Add them to a dictionary for easy access\n",
    "model_instances = {\n",
    "    \"llava-1.5-7b-hf\": LLaVA\n",
    "}\n",
    "\n",
    "# Define query and images\n",
    "query = \"This image contains a simple line drawing that forms an acute angle. Estimate the size of the angle. Please report just the number.\"\n",
    "images = [L.GPImage.figure1('angle') for i in range(1)]\n",
    "\n",
    "# Run the evaluator\n",
    "result1 = L.Evaluator.run(images, query, model_instances)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a5332-b8c8-4f66-ab79-9713e00abd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
